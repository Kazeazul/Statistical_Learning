{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea_1 - Regresión lineal con Tensorflow\n",
    "***\n",
    "Se importan las librerias con las que se van a trabajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, numpy as np, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Carga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = np.load(\"proyecto_training_data.npy\").astype(np.float32)\n",
    "data_X = data_set[::,1].astype(np.float32)\n",
    "data_Y = data_set[::,0].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Creación grafo del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "grafo = tf.Graph()\n",
    "with grafo.as_default() as g:\n",
    "    X = tf.placeholder(\"float\", name = \"X\")\n",
    "    Y = tf.placeholder(\"float\", name = \"Y\")\n",
    "    learning_rate = tf.placeholder(\"float\", name = \"learning_rate\")\n",
    "\n",
    "    W = tf.Variable(0, name = \"W\", dtype = \"float\")\n",
    "    b = tf.Variable(0, name = \"b\", dtype = \"float\")\n",
    "\n",
    "    with tf.name_scope('y_hat') as scope:\n",
    "        y_hat = tf.add(tf.multiply(X, W), b)\n",
    "    with tf.name_scope('cost') as scope:\n",
    "        cost = tf.multiply(tf.reduce_mean(tf.pow(y_hat-Y,2.0)), 0.5)\n",
    "    with tf.name_scope('optimizer') as scope:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    init = tf.global_variables_initializer()\n",
    "    summary = tf.summary.scalar(name='Learning_rate', tensor=cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"grafo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Función de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenamiento(t_epoch, lr):\n",
    "    with tf.Session(graph = grafo) as sess:\n",
    "        writer = tf.summary.FileWriter('./graphs/lr_prueba', sess.graph)\n",
    "        sess.run(init)\n",
    "        for epoch in range(t_epoch):\n",
    "            sess.run(optimizer, feed_dict = {X : data_X, Y : data_Y, learning_rate : lr})\n",
    "            training_cost, weight, bias = sess.run([cost, W, b], feed_dict = {X: data_X, Y: data_Y, learning_rate : lr})\n",
    "            costo = sess.run(cost, feed_dict = {X : data_X, Y : data_Y})\n",
    "            #writer.add_summary(costo, epoch+1)\n",
    "            #No me fue posible realizar las gráficas de learning rate,\n",
    "            #Cada vez que intentaba correr .add_summary siempre me aparecia este error: 'numpy.float32' object has no attribute 'value'\n",
    "            #No encontre solución para mi problema :c\n",
    "            if (epoch + 1) % 50 == 0:\n",
    "                #training_cost, weight, bias = sess.run([cost, W, b], feed_dict = {X: data_X, Y: data_Y, learning_rate : lr})\n",
    "                print(\"Epoch\", (epoch + 1), \": cost =\", training_cost, \"W =\", weight, \"b =\", bias)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Hipotesis\n",
    "\n",
    "* Se espera que los valores más altos de learning rate (10, 1) no se encuentre una convergencia porque son saltos muy grandes.\n",
    "* Los valores más pequeños de learning rate (0.001, 0.0001) es posible que se tarde más y necesiten más iteraciones para encontrar la convergencia.\n",
    "* El valor optimo para este caso se podría encontrar entre 0.1 y 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Learning rate = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 : cost = nan W = nan b = nan\n",
      "Epoch 100 : cost = nan W = nan b = nan\n",
      "Epoch 150 : cost = nan W = nan b = nan\n",
      "Epoch 200 : cost = nan W = nan b = nan\n",
      "Epoch 250 : cost = nan W = nan b = nan\n",
      "Epoch 300 : cost = nan W = nan b = nan\n",
      "Epoch 350 : cost = nan W = nan b = nan\n",
      "Epoch 400 : cost = nan W = nan b = nan\n",
      "Epoch 450 : cost = nan W = nan b = nan\n",
      "Epoch 500 : cost = nan W = nan b = nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'cost/Mul:0' shape=() dtype=float32>, nan, nan]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_epoch = 500\n",
    "lr = 10\n",
    "\n",
    "entrenamiento(t_epoch, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 : cost = nan W = nan b = nan\n",
      "Epoch 100 : cost = nan W = nan b = nan\n",
      "Epoch 150 : cost = nan W = nan b = nan\n",
      "Epoch 200 : cost = nan W = nan b = nan\n",
      "Epoch 250 : cost = nan W = nan b = nan\n",
      "Epoch 300 : cost = nan W = nan b = nan\n",
      "Epoch 350 : cost = nan W = nan b = nan\n",
      "Epoch 400 : cost = nan W = nan b = nan\n",
      "Epoch 450 : cost = nan W = nan b = nan\n",
      "Epoch 500 : cost = nan W = nan b = nan\n"
     ]
    }
   ],
   "source": [
    "t_epoch = 500\n",
    "lr = 10\n",
    "\n",
    "entrenamiento(t_epoch, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 : cost = inf W = -2.3763494e+28 b = -3.710226e+27\n",
      "Epoch 100 : cost = nan W = nan b = nan\n",
      "Epoch 150 : cost = nan W = nan b = nan\n",
      "Epoch 200 : cost = nan W = nan b = nan\n",
      "Epoch 250 : cost = nan W = nan b = nan\n",
      "Epoch 300 : cost = nan W = nan b = nan\n",
      "Epoch 350 : cost = nan W = nan b = nan\n",
      "Epoch 400 : cost = nan W = nan b = nan\n",
      "Epoch 450 : cost = nan W = nan b = nan\n",
      "Epoch 500 : cost = nan W = nan b = nan\n"
     ]
    }
   ],
   "source": [
    "t_epoch = 500\n",
    "lr = 0.1\n",
    "\n",
    "entrenamiento(t_epoch, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 : cost = 1417366500.0 W = 30062.447 b = 2258.235\n",
      "Epoch 100 : cost = 1406327800.0 W = 30424.896 b = -63.207966\n",
      "Epoch 150 : cost = 1395803100.0 W = 30778.8 b = -2329.9197\n",
      "Epoch 200 : cost = 1385769300.0 W = 31124.361 b = -4543.193\n",
      "Epoch 250 : cost = 1376202600.0 W = 31461.777 b = -6704.2827\n",
      "Epoch 300 : cost = 1367081900.0 W = 31791.234 b = -8814.421\n",
      "Epoch 350 : cost = 1358386200.0 W = 32112.926 b = -10874.81\n",
      "Epoch 400 : cost = 1350095700.0 W = 32427.031 b = -12886.621\n",
      "Epoch 450 : cost = 1342191600.0 W = 32733.734 b = -14851.002\n",
      "Epoch 500 : cost = 1334655500.0 W = 33033.203 b = -16769.066\n"
     ]
    }
   ],
   "source": [
    "t_epoch = 500\n",
    "lr = 0.01\n",
    "\n",
    "entrenamiento(t_epoch, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 : cost = 1730887800.0 W = 25885.385 b = 3795.4014\n",
      "Epoch 100 : cost = 1431664500.0 W = 29268.674 b = 4078.1091\n",
      "Epoch 150 : cost = 1425498900.0 W = 29739.111 b = 3906.6157\n",
      "Epoch 200 : cost = 1424249900.0 W = 29832.42 b = 3676.824\n",
      "Epoch 250 : cost = 1423087600.0 W = 29876.832 b = 3439.981\n",
      "Epoch 300 : cost = 1421932900.0 W = 29914.84 b = 3202.7173\n",
      "Epoch 350 : cost = 1420784000.0 W = 29951.941 b = 2965.892\n",
      "Epoch 400 : cost = 1419640000.0 W = 29988.844 b = 2729.615\n",
      "Epoch 450 : cost = 1418501800.0 W = 30025.648 b = 2493.8997\n",
      "Epoch 500 : cost = 1417369100.0 W = 30062.367 b = 2258.7466\n"
     ]
    }
   ],
   "source": [
    "t_epoch = 500\n",
    "lr = 0.001\n",
    "\n",
    "entrenamiento(t_epoch, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 : cost = 13537712000.0 W = 5403.577 b = 819.0298\n",
      "Epoch 100 : cost = 9533714000.0 W = 9825.109 b = 1484.7379\n",
      "Epoch 150 : cost = 6853623300.0 W = 13443.199 b = 2025.0093\n",
      "Epoch 200 : cost = 5059682300.0 W = 16403.965 b = 2462.6577\n",
      "Epoch 250 : cost = 3858878200.0 W = 18826.953 b = 2816.348\n",
      "Epoch 300 : cost = 3055090700.0 W = 20809.963 b = 3101.3486\n",
      "Epoch 350 : cost = 2517043000.0 W = 22433.006 b = 3330.1553\n",
      "Epoch 400 : cost = 2156863000.0 W = 23761.562 b = 3512.9873\n",
      "Epoch 450 : cost = 1915741600.0 W = 24849.174 b = 3658.2068\n",
      "Epoch 500 : cost = 1754309200.0 W = 25739.666 b = 3772.657\n",
      "[<tf.Tensor 'cost/Mul:0' shape=() dtype=float32>, 25739.666, 3772.657]\n"
     ]
    }
   ],
   "source": [
    "t_epoch = 500\n",
    "lr = 0.0001\n",
    "\n",
    "entrenamiento(t_epoch, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Conclusión\n",
    "\n",
    "Al analizar el patrón de resultado del entrenamiento del modelo se puede apreciar que efectivamente los valores para learning rate de 10 y 1 no son aptos para este caso porque son demasiado grandes provocando que no se llegue a la convergencia.\n",
    "\n",
    "También se puede apreciar que el valor de 0.1 no converge, este valor resultó ser engañoso (si fue posible realizar algunas iteraciones)\n",
    "\n",
    "El valor ideal para este caso resultó ser el de 0.01, se aprecia que el costo es el menor de todos los casos y converge con una mayor rapidez.\n",
    "\n",
    "Los valores más pequeños convergen aunque necesitan más iteraciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
